accum_grad: 4
collate_conf:
  norm_mean: true
  norm_var: true
  spec_aug: true
dataset_conf:
  batch_size: 24
  batch_type: static
  max_length: 10240
  min_length: 0
  sort: true
decoder: transformer
decoder_conf:
  attention_heads: 4
  dropout_rate: 0.1
  linear_units: 2048
  num_blocks: 6
  positional_dropout_rate: 0.1
  self_attention_dropout_rate: 0.0
  src_attention_dropout_rate: 0.0
encoder: transformer
encoder_conf:
  attention_dropout_rate: 0.0
  attention_heads: 4
  dropout_rate: 0.1
  input_layer: conv2d
  linear_units: 2048
  normalize_before: true
  num_blocks: 12
  output_size: 256
  positional_dropout_rate: 0.1
grad_clip: 5
input_dim: 83
log_interval: 100
max_epoch: 80
model_conf:
  ctc_weight: 0.3
  length_normalized_loss: false
  lsm_weight: 0.1
optim: adam
optim_conf:
  lr: 0.001
output_dim: 4233
scheduler: warmuplr
scheduler_conf:
  warmup_steps: 25000
